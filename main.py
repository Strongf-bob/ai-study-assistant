"""
AI ĞŸĞ¾Ğ¼Ğ¾Ñ‰Ğ½Ğ¸Ğº Ğ´Ğ»Ñ ÑƒÑ‡ĞµĞ±Ñ‹ - Ğ£Ğ¿Ñ€Ğ¾Ñ‰Ñ‘Ğ½Ğ½Ğ°Ñ Ğ²ĞµÑ€ÑĞ¸Ñ Ğ´Ğ»Ñ Python 3.13
"""
from ollama_client import OllamaClient
from simple_storage import SimpleStorage
from scheduler import SimpleScheduler
from config import settings


class StudyAssistantSimple:
    """Ğ£Ğ¿Ñ€Ğ¾Ñ‰Ñ‘Ğ½Ğ½Ğ°Ñ Ğ²ĞµÑ€ÑĞ¸Ñ Ğ´Ğ»Ñ Python 3.13"""

    def __init__(self):
        print("ğŸš€ Ğ˜Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ AI ĞŸĞ¾Ğ¼Ğ¾Ñ‰Ğ½Ğ¸ĞºĞ° (ÑƒĞ¿Ñ€Ğ¾Ñ‰Ñ‘Ğ½Ğ½Ğ°Ñ Ğ²ĞµÑ€ÑĞ¸Ñ)...\n")

        print("ğŸ“¡ ĞŸĞ¾Ğ´ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ğµ Ğº Ollama...")
        self.llm = OllamaClient()

        print("ğŸ’¾ Ğ˜Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ñ…Ñ€Ğ°Ğ½Ğ¸Ğ»Ğ¸Ñ‰Ğ°...")
        self.storage = SimpleStorage()

        print("ğŸ“… Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ğ¿Ğ»Ğ°Ğ½Ğ¸Ñ€Ğ¾Ğ²Ñ‰Ğ¸ĞºĞ°...")
        self.scheduler = SimpleScheduler()

        self.user_profile = {
            "name": "Ğ¡Ñ‚ÑƒĞ´ĞµĞ½Ñ‚",
            "learning_style": "visual",
            "level": "intermediate"
        }

        print("\nâœ… Ğ“Ğ¾Ñ‚Ğ¾Ğ² Ğº Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğµ!\n")

    def check_ollama(self) -> bool:
        if not self.llm.check_connection():
            print("âŒ Ollama Ğ½Ğµ Ğ·Ğ°Ğ¿ÑƒÑ‰ĞµĞ½!")
            print("\nĞ”Ğ»Ñ Ğ·Ğ°Ğ¿ÑƒÑĞºĞ°:")
            print("1. Ğ£ÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ¸ Ollama: https://ollama.com")
            print(f"2. Ğ¡ĞºĞ°Ñ‡Ğ°Ğ¹ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ: ollama pull {settings.OLLAMA_MODEL}")
            print("3. Ğ—Ğ°Ğ¿ÑƒÑÑ‚Ğ¸: ollama serve")
            return False
        return True

    def process_query(self, query: str) -> str:
        query_lower = query.lower()

        if any(w in query_lower for w in ["Ğ¿Ğ»Ğ°Ğ½", "Ñ€Ğ°ÑĞ¿Ğ»Ğ°Ğ½Ğ¸Ñ€ÑƒĞ¹"]):
            return self._handle_planning(query)

        elif any(w in query_lower for w in ["Ğ¾Ğ±ÑŠÑÑĞ½Ğ¸", "Ñ‡Ñ‚Ğ¾ Ñ‚Ğ°ĞºĞ¾Ğµ"]):
            return self._handle_explanation(query)

        elif any(w in query_lower for w in ["Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸", "Ğ´ĞµĞ»Ğ°"]):
            return self.scheduler.format_task_list()

        elif any(w in query_lower for w in ["Ñ‚ĞµÑÑ‚", "quiz"]):
            return self._handle_quiz(query)

        else:
            return self.storage.generate_answer_with_context(query, self.llm)

    def _handle_planning(self, query: str) -> str:
        subject = "ĞĞ±Ñ‰ĞµĞµ"
        for subj in ["Ğ¼Ğ°Ñ‚ĞµĞ¼Ğ°Ñ‚Ğ¸ĞºĞ°", "Ñ„Ğ¸Ğ·Ğ¸ĞºĞ°", "python", "Ğ¿Ñ€Ğ¾Ğ³Ñ€Ğ°Ğ¼Ğ¼Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ"]:
            if subj in query.lower():
                subject = subj.capitalize()
                break

        plan = self.llm.create_study_plan(
            subject, self.user_profile["level"], "ĞÑĞ²Ğ¾Ğ¸Ñ‚ÑŒ Ğ¼Ğ°Ñ‚ĞµÑ€Ğ¸Ğ°Ğ»", 10
        )
        return f"ğŸ“š **ĞŸĞ»Ğ°Ğ½ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ¿Ğ¾ {subject}**\n\n{plan}"

    def _handle_explanation(self, query: str) -> str:
        rag_answer = self.storage.generate_answer_with_context(query, self.llm, 2)

        if "Ğ½Ğµ Ğ½Ğ°ÑˆÑ‘Ğ»" in rag_answer.lower() or len(rag_answer) < 100:
            concept = query.replace("Ğ¾Ğ±ÑŠÑÑĞ½Ğ¸", "").replace("Ñ‡Ñ‚Ğ¾ Ñ‚Ğ°ĞºĞ¾Ğµ", "").strip()
            return self.llm.explain_concept(
                concept, self.user_profile["learning_style"], self.user_profile["level"]
            )

        return rag_answer

    def _handle_quiz(self, query: str) -> str:
        topic = query.replace("Ñ‚ĞµÑÑ‚", "").replace("quiz", "").replace("Ğ¿Ğ¾", "").strip()
        if not topic or len(topic) < 3:
            topic = "Ğ¾Ğ±Ñ‰Ğ¸Ğµ Ğ·Ğ½Ğ°Ğ½Ğ¸Ñ"

        quiz = self.llm.generate_quiz(topic, 5, self.user_profile["level"])
        return f"ğŸ“ **Ğ¢ĞµÑÑ‚: {topic}**\n\n{quiz}"

    def add_material(self, text: str, subject: str = "Ğ¾Ğ±Ñ‰ĞµĞµ") -> bool:
        return self.storage.add_document(text, {"subject": subject})

    def add_task(self, title: str, subject: str, days: int = 7, priority: str = "medium"):
        self.scheduler.add_task(title, subject, days, priority=priority)
        return True

    def show_help(self):
        print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘     AI ĞŸĞĞœĞĞ©ĞĞ˜Ğš Ğ”Ğ›Ğ¯ Ğ£Ğ§Ğ•Ğ‘Ğ« (Ğ£Ğ¿Ñ€Ğ¾Ñ‰Ñ‘Ğ½Ğ½Ğ°Ñ Ğ²ĞµÑ€ÑĞ¸Ñ)           â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“– ĞšĞĞœĞĞĞ”Ğ«:

ğŸ¯ ĞŸĞ›ĞĞĞ˜Ğ ĞĞ’ĞĞĞ˜Ğ•:
   â€¢ "Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ¹ Ğ¿Ğ»Ğ°Ğ½ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ¿Ğ¾ Ğ¼Ğ°Ñ‚ĞµĞ¼Ğ°Ñ‚Ğ¸ĞºĞµ"

ğŸ“š ĞĞ‘Ğ£Ğ§Ğ•ĞĞ˜Ğ•:
   â€¢ "ĞĞ±ÑŠÑÑĞ½Ğ¸ Ñ‡Ñ‚Ğ¾ Ñ‚Ğ°ĞºĞ¾Ğµ Ñ€ĞµĞºÑƒÑ€ÑĞ¸Ñ"

âœ… Ğ—ĞĞ”ĞĞ§Ğ˜:
   â€¢ "ĞŸĞ¾ĞºĞ°Ğ¶Ğ¸ Ğ¼Ğ¾Ğ¸ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸"

ğŸ“ Ğ¢Ğ•Ğ¡Ğ¢Ğ«:
   â€¢ "Ğ¢ĞµÑÑ‚ Ğ¿Ğ¾ Ñ„Ğ¸Ğ·Ğ¸ĞºĞµ"

ğŸ’¾ Ğ£ĞŸĞ ĞĞ’Ğ›Ğ•ĞĞ˜Ğ•:
   â€¢ help - ÑĞ¿Ñ€Ğ°Ğ²ĞºĞ°
   â€¢ stats - ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ°
   â€¢ exit - Ğ²Ñ‹Ñ…Ğ¾Ğ´

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
âœ¨ Ğ£Ğ¿Ñ€Ğ¾Ñ‰Ñ‘Ğ½Ğ½Ğ°Ñ Ğ²ĞµÑ€ÑĞ¸Ñ Ğ´Ğ»Ñ Python 3.13:
   â€¢ LLM: Ollama + Llama 3.2
   â€¢ Ğ¥Ñ€Ğ°Ğ½Ğ¸Ğ»Ğ¸Ñ‰Ğµ: JSON Ñ„Ğ°Ğ¹Ğ»Ñ‹ (Ğ±ĞµĞ· ChromaDB)
   â€¢ 100% Ğ±ĞµÑĞ¿Ğ»Ğ°Ñ‚Ğ½Ğ¾ Ğ¸ Ğ»Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ğ¾!
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
""")

    def show_stats(self):
        print("\nğŸ“Š Ğ¡Ğ¢ĞĞ¢Ğ˜Ğ¡Ğ¢Ğ˜ĞšĞ:")
        print("=" * 50)

        task_stats = self.scheduler.get_stats()
        print(f"\nâœ… Ğ—Ğ°Ğ´Ğ°Ñ‡Ğ¸:")
        print(f"   Ğ’ÑĞµĞ³Ğ¾: {task_stats['total']}")
        print(f"   Ğ’Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¾: {task_stats['completed']}")
        print(f"   ĞŸÑ€Ğ¾Ğ³Ñ€ĞµÑÑ: {task_stats['completion_rate']}%")

        storage_stats = self.storage.get_stats()
        print(f"\nğŸ“š Ğ‘Ğ°Ğ·Ğ° Ğ·Ğ½Ğ°Ğ½Ğ¸Ğ¹:")
        print(f"   Ğ”Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ¾Ğ²: {storage_stats['total_documents']}")

        print(f"\nğŸ¤– AI:")
        print(f"   ĞœĞ¾Ğ´ĞµĞ»ÑŒ: {settings.OLLAMA_MODEL}")
        print(f"   Ğ¡Ñ‚Ğ°Ñ‚ÑƒÑ: {'ğŸŸ¢ ĞŸĞ¾Ğ´ĞºĞ»ÑÑ‡ĞµĞ½Ğ°' if self.llm.check_connection() else 'ğŸ”´ ĞĞµ Ğ¿Ğ¾Ğ´ĞºĞ»ÑÑ‡ĞµĞ½Ğ°'}")
        print("=" * 50)

    def run(self):
        if not self.check_ollama():
            return

        self.show_help()
        print("\nğŸ’¬ ĞĞ°Ñ‡Ğ½Ğ¸ Ğ´Ğ¸Ğ°Ğ»Ğ¾Ğ³!\n")

        while True:
            try:
                user_input = input("\nğŸ‘¤ Ğ’Ñ‹: ").strip()

                if not user_input:
                    continue

                if user_input.lower() in ["exit", "Ğ²Ñ‹Ñ…Ğ¾Ğ´", "quit"]:
                    print("\nğŸ‘‹ Ğ”Ğ¾ Ğ²ÑÑ‚Ñ€ĞµÑ‡Ğ¸!")
                    break

                elif user_input.lower() == "help":
                    self.show_help()
                    continue

                elif user_input.lower() == "stats":
                    self.show_stats()
                    continue

                print("\nğŸ¤– ĞÑÑĞ¸ÑÑ‚ĞµĞ½Ñ‚: ", end="", flush=True)
                response = self.process_query(user_input)
                print(response)

            except KeyboardInterrupt:
                print("\n\nğŸ‘‹ Ğ”Ğ¾ Ğ²ÑÑ‚Ñ€ĞµÑ‡Ğ¸!")
                break
            except Exception as e:
                print(f"\nâŒ ĞÑˆĞ¸Ğ±ĞºĞ°: {e}")


def main():
    assistant = StudyAssistantSimple()

    # Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ñ‹
    print("ğŸ“ Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑÑ Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ñ‹ Ğ¼Ğ°Ñ‚ĞµÑ€Ğ¸Ğ°Ğ»Ğ¾Ğ²...\n")

    assistant.add_material(
        "Python - Ğ²Ñ‹ÑĞ¾ĞºĞ¾ÑƒÑ€Ğ¾Ğ²Ğ½ĞµĞ²Ñ‹Ğ¹ ÑĞ·Ñ‹Ğº Ğ¿Ñ€Ğ¾Ğ³Ñ€Ğ°Ğ¼Ğ¼Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ. "
        "ĞŸÑ€Ğ¾ÑÑ‚Ğ¾Ğ¹ ÑĞ¸Ğ½Ñ‚Ğ°ĞºÑĞ¸Ñ. Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ÑÑ Ğ´Ğ»Ñ Ğ²ĞµĞ±-Ñ€Ğ°Ğ·Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸, Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ° Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…, ML.",
        "programming"
    )

    assistant.add_material(
        "Ğ ĞµĞºÑƒÑ€ÑĞ¸Ñ - Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ñ Ğ²Ñ‹Ğ·Ñ‹Ğ²Ğ°ĞµÑ‚ ÑĞ°Ğ¼Ğ° ÑĞµĞ±Ñ. "
        "ĞÑƒĞ¶ĞµĞ½ Ğ±Ğ°Ğ·Ğ¾Ğ²Ñ‹Ğ¹ ÑĞ»ÑƒÑ‡Ğ°Ğ¹. ĞŸÑ€Ğ¸Ğ¼ĞµÑ€: Ñ„Ğ°ĞºÑ‚Ğ¾Ñ€Ğ¸Ğ°Ğ».",
        "programming"
    )

    assistant.add_task("Ğ ĞµÑˆĞ¸Ñ‚ÑŒ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸ Ğ¿Ğ¾ Ğ°Ğ»Ğ³ĞµĞ±Ñ€Ğµ", "ĞœĞ°Ñ‚ĞµĞ¼Ğ°Ñ‚Ğ¸ĞºĞ°", 2, "high")
    assistant.add_task("ĞŸÑ€Ğ¾Ñ‡Ğ¸Ñ‚Ğ°Ñ‚ÑŒ Ğ³Ğ»Ğ°Ğ²Ñƒ Ğ¿Ğ¾ Ñ„Ğ¸Ğ·Ğ¸ĞºĞµ", "Ğ¤Ğ¸Ğ·Ğ¸ĞºĞ°", 3)

    assistant.run()


if __name__ == "__main__":
    main()
